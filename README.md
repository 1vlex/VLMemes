# VLMemes: классификация токсичных мемов (VLM + CLIP)

> ⚠️ **Внимание:** в проекте и примерах данных присутствует нецензурная
> и оскорбительная лексика.
> Это обусловлено спецификой задачи анализа токсичных мемов и используется
> исключительно в исследовательских целях.
> Содержимое проекта не отражает позицию автора.

---

## Описание проекта

`VLMemes` - исследовательский проект в формате Jupyter-ноутбука (`VLMemes.ipynb`),
посвященный анализу того, как мультимодальные модели работают
с русскоязычными мемами и задачей детекции токсичности.

В проекте сравниваются два подхода:
- генеративная мультимодальная модель **Qwen2.5-VL-3B-Instruct**;
- контрастивная модель **CLIP (ViT-L/14)**.

Цель работы - исследование поведения VLM и CLIP на небольшом вручную
размеченном датасете токсичных и нейтральных мемов.

---

## Пайплайн исследования

Основные этапы ноутбука:

1. Сбор аннотаций из локальных папок с мемами (`Негативно` / `Нейтрально`)
   и формирование `annotations.csv`.
2. Визуальный обзор и первичный анализ датасета.
3. OCR (`easyocr`) для извлечения русского текста из изображений мемов.
4. VLM (Qwen2.5-VL-3B-Instruct):
   - формирование русскоязычного промпта под задачу модерации контента;
   - генерация ответа модели (класс и объяснение);
   - парсинг ответа в метку `toxic` или `non_toxic`.
5. CLIP (openai/clip-vit-large-patch14):
   - текстовые описания классов («токсичный мем», «нейтральный мем»);
   - учет OCR текста при формировании текстовых промптов;
   - вычисление вероятностей классов по изображению и тексту.
6. Оценка качества моделей:
   - accuracy, precision, recall, F1;
   - confusion matrix;
   - сравнительный анализ VLM и CLIP.
7. Интерпретация CLIP (`pytorch-grad-cam`):
   - построение heatmap (EigenCAM);
   - анализ областей изображения, влияющих на решение модели.

---

## Структура проекта

Фактическая структура репозитория:

```text
.
├─ VLMemes.ipynb
├─ memes_project/
│   ├─ memes/
│   │   ├─ Негативно/
│   │   └─ Нейтрально/
│   └─ 
├─ requirements.txt
├─ .gitignore
└─ README.md
```

Все пути в ноутбуке настроены на работу с папкой `memes_project`,
расположенной в корне репозитория.

---

## Данные

Используется небольшой вручную размеченный набор мемов:
- `Негативно` (`toxic`) - агрессивная или токсичная подача;
- `Нейтрально` (`non_toxic`) - нейтральные мемы.

В текущем наборе данных:
- 26 негативных мемов;
- 25 нейтральных мемов.

Ноутбук автоматически:
1. сканирует папки с мемами;
2. формирует `annotations.csv`;
3. использует его для inference и оценки моделей.

---

## Зависимости

Основные библиотеки, используемые в проекте:

- torch, torchvision, torchaudio
- transformers, accelerate, bitsandbytes
- numpy, pandas
- matplotlib
- scikit-learn
- opencv-python
- pillow
- tqdm
- easyocr
- pytorch-grad-cam
- jupyter

Полный список зависимостей приведен в `requirements.txt`.

---

## Запуск проекта

```bash
git clone https://github.com/1vlex/VLMemes.git
cd VLMemes

python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

pip install --upgrade pip
pip install -r requirements.txt

jupyter notebook
# открыть VLMemes.ipynb
```

Для запуска модели Qwen2.5-VL рекомендуется использовать GPU.
На CPU запуск возможен, но inference будет значительно медленнее.
